{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nomic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-community nomic pyPDF2 pandas sentence-transformers transformers torch > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nomic\n",
    "import time\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader  # Importing PDF loader from Langchain\n",
    "from langchain.vectorstores import AtlasDB\n",
    "from langchain.document_loaders import TextLoader\n",
    "from nomic import atlas\n",
    "nomic.login('<[place nomi key here]>') #api key to a limited demo account. Make your own account at atlas.nomic.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90404/2766102236.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embedd = HuggingFaceEmbeddings()\n",
      "/tmp/ipykernel_90404/2766102236.py:1: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embedd = HuggingFaceEmbeddings()\n",
      "/home/vscode/my-envs/03-rag-graph-databases/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/vscode/my-envs/03-rag-graph-databases/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedd = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Create the Nomic example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-11 03:21:06.009\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_data\u001b[0m:\u001b[36m128\u001b[0m - \u001b[33m\u001b[1mAn ID field was not specified in your data so one was generated for you in insertion order.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                               text  label\n",
      "0          0  Nasdaq planning \\$100m-share sale The owner of...      2\n",
      "1          1  Report urges shuttle mission to service Hubble...      3\n",
      "2          2  Update 5: Euro Reaches New High Against US Dol...      0\n",
      "3          3  Franz wins downhill, Guay 13th VAL D #39;ISERE...      1\n",
      "4          4  Creative plans US\\$100m advertising campaign f...      3\n",
      "...      ...                                                ...    ...\n",
      "24995  24995  F1: British GP 'saved by deal' Formula One bos...      0\n",
      "24996  24996  Asia Shares Higher on BOJ Survey; Gold Up (Reu...      2\n",
      "24997  24997  News In Brief The speedy GeForce Go 6800 mobil...      3\n",
      "24998  24998  US Stocks Gain on Optimism About Election; Nex...      2\n",
      "24999  24999  Parents to Read 9/11 Victims' Names NEW YORK -...      0\n",
      "\n",
      "[25000 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-11 03:21:07.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m857\u001b[0m - \u001b[1mCreating dataset `inquisitive-newton`\u001b[0m\n",
      "\u001b[32m2024-09-11 03:21:08.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_data\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mUploading data to Atlas.\u001b[0m\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.83it/s]\n",
      "\u001b[32m2024-09-11 03:21:09.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_add_data\u001b[0m:\u001b[36m1668\u001b[0m - \u001b[1mUpload succeeded.\u001b[0m\n",
      "\u001b[32m2024-09-11 03:21:09.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_data\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1m`botchagalupe/inquisitive-newton`: Data upload succeeded to dataset`\u001b[0m\n",
      "\u001b[32m2024-09-11 03:21:11.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mcreate_index\u001b[0m:\u001b[36m1262\u001b[0m - \u001b[1mCreated map `inquisitive-newton` in dataset `botchagalupe/inquisitive-newton`: https://atlas.nomic.ai/data/botchagalupe/inquisitive-newton\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inquisitive-newton: https://atlas.nomic.ai/data/botchagalupe/inquisitive-newton\n"
     ]
    }
   ],
   "source": [
    "# Example from Nomic 25k news articles\n",
    "from nomic import atlas\n",
    "import pandas\n",
    "\n",
    "news_articles = pandas.read_csv('https://raw.githubusercontent.com/nomic-ai/maps/main/data/ag_news_25k.csv')\n",
    "\n",
    "print(news_articles)\n",
    "\n",
    "dataset = atlas.map_data(data=news_articles, indexed_field='text')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Create the Nomic Void dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/papers/aiayn.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpypdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PdfReader\n\u001b[0;32m----> 3\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[43mPdfReader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/papers/aiayn.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m pdf_texts \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mextract_text()\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mpages]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Filter the empty strings\u001b[39;00m\n",
      "File \u001b[0;32m~/my-envs/03-rag-graph-databases/lib/python3.12/site-packages/pypdf/_reader.py:134\u001b[0m, in \u001b[0;36mPdfReader.__init__\u001b[0;34m(self, stream, strict, password)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream_opened \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream, (\u001b[38;5;28mstr\u001b[39m, Path)):\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    135\u001b[0m         stream \u001b[38;5;241m=\u001b[39m BytesIO(fh\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream_opened \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/papers/aiayn.pdf'"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(\"../data/papers/aiayn.pdf\")\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "\n",
    "# Filter the empty strings\n",
    "pdf_texts = [text for text in pdf_texts if text]\n",
    "\n",
    "#print(word_wrap(pdf_texts[0]))\n",
    "print(pdf_texts[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk#=0 Chunk=JohnWillis-AI-Frankendraftv21\n",
      "THERISEOFAI\n",
      "UnmaskingtheMagicofChatGPT\n",
      "JohnWillis\n",
      "\n",
      "JohnWillis-AI-Frankendraftv22\n",
      "Contents\n",
      "Contents2Foreword/Testimonials3Prologue4—PartI:HowAIBegan—51|PrometheanFireorPandora’sBox?62|Myth&Legend193|TheLittleEnginesThatCouldn’t264|SecretIntelligence315|Aberdeen376|ProveYou’reNotaRobot447|TheMagicMouseofBellLabs498|TheSummerItStarted559|ThinkinginHuman6110|ArtiﬁcialExpert7211|TheBigBlueBrute81—PartII:HowAILearns—8812|ThePitts8913|TheFrog’sEye9914|Chess&Checkers10715|DeepBluevs.DeepLearning118—PartIII:HowAIReads—12416|TheRayKurzweilShow12517|TeachingAItheABCsand123s131—PartIV:HowAISees—13718|AI’sEyeballs13819|AIsandAVs14420|TheLittleGPUThatCould15321|Fei-FeiLiTeachesAItoSee157—PartV:HowAISpeaks—16822|IfItQuacksLikeaDuck…16923|TheStoryofSiri178Acknowledgments179\n",
      "\n",
      "JohnWillis-AI-Frankendraftv23\n",
      "Foreword/Testimonials\n",
      "DarrenHaasJohnAllsparDr.Woods \n",
      "\n",
      "Chunk#=1 Chunk=JohnWillis-AI-Frankendraftv24\n",
      "Prologue\n",
      "[storyoffeedingDomenicoLepore’sbookTheHumanConditionintoClaude]\n",
      "[atExxon,promotiontoruncomputer/consoleoperator]\n",
      "[theme:atsomepoint,itgetssonormalized,itdoesn’tmatter;youjustexpectit;\n",
      "itworks]\n",
      "[theElektroEﬀect;it’snotmagiconceyouunderstandit]\n",
      "\n",
      "JohnWillis-AI-Frankendraftv25\n",
      "—PartI:HowAIBegan— \n",
      "\n",
      "Chunk#=2 Chunk=JohnWillis-AI-Frankendraftv26\n",
      "1|PrometheanFireorPandora’sBox?\n",
      "“Assoonasitworks,noonecallsitAIanymore.”\n",
      "—JohnMcCarthy1\n",
      "“Will…you…tell…your…story…please?”2\n",
      "Soundinglikeanold-timeyradioannouncer,themanspokethesewordsintoa\n",
      "telephonereceiver,pausingbetweeneachword.Hestoodonasemicircularplatform\n",
      "raisedseveralfeetabovethegatheredcrowd.TohisrightstoodElektro,agolden,\n",
      "gleamingmetalmanoversixfeettall.\n",
      "Afterasmallpause,thecrowdheardthewords,“...who?…me?”\n",
      "Thepresenterquicklysaid,“Yes,you.”\n",
      "Almostasiffollowingarhythmicbeat,therobotsaid,“Okay,toots,”earning\n",
      "laughterfromthespectators.Withoutbreakingthebeat,theartiﬁcialmancontinued,\n",
      "2https://www.youtube.com/watch?v=AuyTRbj8QSA1M.Y.Vardi,“Artiﬁcialintelligence:PastandFuture,”CommunicationsoftheASsociationforComputingMachinery55,no1(2012):5: \n",
      "\n",
      "Chunk#=3 Chunk=JohnWillis-AI-Frankendraftv27\n",
      "“Lad-ies…and…gen-tle-men…I’d…be…very…glad…to…tell…my…story?”He\n",
      "inﬂectedtheendofthelastwordasifitwereaquestion.Thespeechwaschoppyand\n",
      "stilted;oddandunnatural.“I…am…a…smart…fel-low…as\n",
      "I…have…a…ver-y…ﬁne…brain…”Therewasnoquestionabouttheoddemphasison\n",
      "thewordﬁne.Hecontinued,\n",
      "“…of…for-ty-eight…e-lec-tri-cal…re-lays…It…works…just…like…a…tel-e-phone…sw\n",
      "itch-board.”3\n",
      "Ofallthewondersofthe1939’sWorld’sFairinNewYork,Elektrowasoneofthe\n",
      "highlights,amarvelofhumaningenuity.Therobotcouldwalk,talk,makejokes,and\n",
      "evensmokeacigarette!Ifyoucouldseehim,youwouldinstantlyrecognizehislikeness\n",
      "asbeinginspiredbytheArtDeco-likeroboticmenoftendepictedincomicsand\n",
      "drawingsfromthe1920s.Whatabreakthroughoftechnology!Toﬁnallyhavean\n",
      "artiﬁcialpersonwhocouldtakecommandsandevenhadhisownpersonality?\n",
      "Humankindhadbeendreamingaboutsuchbeingsformillennia.Nowonderthepeople\n",
      "listeningtoElektrobelievedwewouldhaveﬂyingcarsbytheendofthecentury.The \n",
      "\n",
      "Chunk#=4 Chunk=futureseemedlimitless.Intheyearstocome,ElektrowouldtourtheUSaccompanied\n",
      "byhisdog.“Sparko”isconsideredtheworld’sﬁrstanimatronic,thegreat-grandfather\n",
      "tothosenightmare-inducinganimatronicsfromChuckE.Cheeseandthe1950sridesat\n",
      "Disneyland.\n",
      "Thesmokingrobotdidn’tunderstandEnglishanymorethantheelectricalrelays\n",
      "ofhisinnardsspokeSwahili.Therobotwasasleek,cleverlyengineeredpieceof\n",
      "machinerywhosecomponentpartscamefromtechnologypeoplehadbeenusingfor\n",
      "3https://www.youtube.com/watch?v=AuyTRbj8QSA \n",
      "\n",
      "\n",
      "Total chunks: 303\n"
     ]
    }
   ],
   "source": [
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    #separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
    "\n",
    "#print(character_split_texts)\n",
    "for i in range(5):\n",
    "    print(\"Chunk#=\" + str(i) + \" Chunk=\" + character_split_texts[i],\"\\n\")\n",
    "\n",
    "print(f\"\\nTotal chunks: {len(character_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedd.embed_documents(character_split_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-04 14:48:25.378\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_data\u001b[0m:\u001b[36m128\u001b[0m - \u001b[33m\u001b[1mAn ID field was not specified in your data so one was generated for you in insertion order.\u001b[0m\n",
      "\u001b[32m2024-09-04 14:48:29.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m857\u001b[0m - \u001b[1mCreating dataset `tenacious-rubin`\u001b[0m\n",
      "\u001b[32m2024-09-04 14:48:29.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_data\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mUploading data to Atlas.\u001b[0m\n",
      "/home/vscode/.local/lib/python3.12/site-packages/nomic/dataset.py:1485: UserWarning: The DataFrame has column names of mixed type. They will be converted to strings and not roundtrip correctly.\n",
      "  data = pa.Table.from_pandas(data)\n",
      "1it [00:05,  5.72s/it]\n",
      "\u001b[32m2024-09-04 14:48:36.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_add_data\u001b[0m:\u001b[36m1668\u001b[0m - \u001b[1mUpload succeeded.\u001b[0m\n",
      "\u001b[32m2024-09-04 14:48:36.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_data\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1m`botchagalupe/tenacious-rubin`: Data upload succeeded to dataset`\u001b[0m\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Indexing on text not allowed. Valid options are: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '390', '391', '392', '393', '394', '395', '396', '397', '398', '399', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '450', '451', '452', '453', '454', '455', '456', '457', '458', '459', '460', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473', '474', '475', '476', '477', '478', '479', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '490', '491', '492', '493', '494', '495', '496', '497', '498', '499', '500', '501', '502', '503', '504', '505', '506', '507', '508', '509', '510', '511', '512', '513', '514', '515', '516', '517', '518', '519', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '530', '531', '532', '533', '534', '535', '536', '537', '538', '539', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '550', '551', '552', '553', '554', '555', '556', '557', '558', '559', '560', '561', '562', '563', '564', '565', '566', '567', '568', '569', '570', '571', '572', '573', '574', '575', '576', '577', '578', '579', '580', '581', '582', '583', '584', '585', '586', '587', '588', '589', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '600', '601', '602', '603', '604', '605', '606', '607', '608', '609', '610', '611', '612', '613', '614', '615', '616', '617', '618', '619', '620', '621', '622', '623', '624', '625', '626', '627', '628', '629', '630', '631', '632', '633', '634', '635', '636', '637', '638', '639', '640', '641', '642', '643', '644', '645', '646', '647', '648', '649', '650', '651', '652', '653', '654', '655', '656', '657', '658', '659', '660', '661', '662', '663', '664', '665', '666', '667', '668', '669', '670', '671', '672', '673', '674', '675', '676', '677', '678', '679', '680', '681', '682', '683', '684', '685', '686', '687', '688', '689', '690', '691', '692', '693', '694', '695', '696', '697', '698', '699', '700', '701', '702', '703', '704', '705', '706', '707', '708', '709', '710', '711', '712', '713', '714', '715', '716', '717', '718', '719', '720', '721', '722', '723', '724', '725', '726', '727', '728', '729', '730', '731', '732', '733', '734', '735', '736', '737', '738', '739', '740', '741', '742', '743', '744', '745', '746', '747', '748', '749', '750', '751', '752', '753', '754', '755', '756', '757', '758', '759', '760', '761', '762', '763', '764', '765', '766', '767', 'id_']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnomic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m atlas\n\u001b[0;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43matlas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexed_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/nomic/atlas.py:160\u001b[0m, in \u001b[0;36mmap_data\u001b[0;34m(data, blobs, embeddings, identifier, description, id_field, is_public, indexed_field, projection, topic_model, duplicate_detection, embedding_model)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    158\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`: Data upload succeeded to dataset`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 160\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexed_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexed_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprojection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprojection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopic_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mduplicate_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mduplicate_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39m_latest_dataset_state()\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/nomic/dataset.py:1169\u001b[0m, in \u001b[0;36mAtlasDataset.create_index\u001b[0;34m(self, name, indexed_field, modality, projection, topic_model, duplicate_detection, embedding_model, reuse_embeddings_from_index)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou did not specify a field to index. Specify an \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindexed_field\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexed_field \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_fields:\n\u001b[0;32m-> 1169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexing on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindexed_field\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not allowed. Valid options are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m topic_model\u001b[38;5;241m.\u001b[39mtopic_label_field \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mException\u001b[0m: Indexing on text not allowed. Valid options are: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '390', '391', '392', '393', '394', '395', '396', '397', '398', '399', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '450', '451', '452', '453', '454', '455', '456', '457', '458', '459', '460', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473', '474', '475', '476', '477', '478', '479', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '490', '491', '492', '493', '494', '495', '496', '497', '498', '499', '500', '501', '502', '503', '504', '505', '506', '507', '508', '509', '510', '511', '512', '513', '514', '515', '516', '517', '518', '519', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '530', '531', '532', '533', '534', '535', '536', '537', '538', '539', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '550', '551', '552', '553', '554', '555', '556', '557', '558', '559', '560', '561', '562', '563', '564', '565', '566', '567', '568', '569', '570', '571', '572', '573', '574', '575', '576', '577', '578', '579', '580', '581', '582', '583', '584', '585', '586', '587', '588', '589', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '600', '601', '602', '603', '604', '605', '606', '607', '608', '609', '610', '611', '612', '613', '614', '615', '616', '617', '618', '619', '620', '621', '622', '623', '624', '625', '626', '627', '628', '629', '630', '631', '632', '633', '634', '635', '636', '637', '638', '639', '640', '641', '642', '643', '644', '645', '646', '647', '648', '649', '650', '651', '652', '653', '654', '655', '656', '657', '658', '659', '660', '661', '662', '663', '664', '665', '666', '667', '668', '669', '670', '671', '672', '673', '674', '675', '676', '677', '678', '679', '680', '681', '682', '683', '684', '685', '686', '687', '688', '689', '690', '691', '692', '693', '694', '695', '696', '697', '698', '699', '700', '701', '702', '703', '704', '705', '706', '707', '708', '709', '710', '711', '712', '713', '714', '715', '716', '717', '718', '719', '720', '721', '722', '723', '724', '725', '726', '727', '728', '729', '730', '731', '732', '733', '734', '735', '736', '737', '738', '739', '740', '741', '742', '743', '744', '745', '746', '747', '748', '749', '750', '751', '752', '753', '754', '755', '756', '757', '758', '759', '760', '761', '762', '763', '764', '765', '766', '767', 'id_']"
     ]
    }
   ],
   "source": [
    "from nomic import atlas\n",
    "\n",
    "dataset = atlas.map_data(data=df\n",
    "\n",
    ", indexed_field='text')\n",
    "print(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
