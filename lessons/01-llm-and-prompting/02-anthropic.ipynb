{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anthropic an alternative model\n",
    "\n",
    "## Introduction\n",
    "After OpenAI came out and was succesful, other companies launched their own Saas LLM:\n",
    "- AWS had their own Titan model\n",
    "- Google had Gemini as their model\n",
    "\n",
    "They all struggled initially. One the companies that was started was *Anthropic*\n",
    "[Anthropic](https://anthropic.com/) is one of the first models to be quality on par with OpenAI.\n",
    "\n",
    "What's interesting is that you can subscribe to them directly, but the model/service is also offered through AWS and Google.\n",
    "\n",
    "## Model types\n",
    "Similar to OpenAI , Anthropic offers a variety of models:\n",
    "- claude-3-5-sonnet-20240620 \n",
    "- claude-3-opus-20240229\n",
    "- claude-3-sonnet-20240229\n",
    "\n",
    "See <https://docs.anthropic.com/en/docs/about-claude/models#model-names> more details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now install the Anthropic SDK . See <https://github.com/anthropics/anthropic-sdk-python>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example using the anthropic API SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message(id='msg_01WQuyJSaVCKabP9rTA4tJkW', content=[TextBlock(text='Generative AI\\nAutomating DevOps flows\\nEfficiency blooms', type='text')], model='claude-3-opus-20240229', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=19, output_tokens=20))\n"
     ]
    }
   ],
   "source": [
    "from anthropic import Anthropic\n",
    "\n",
    "model = \"claude-3-opus-20240229\"\n",
    "question = \"A Haiku about genAI and DevOps\"\n",
    "\n",
    "client = Anthropic(\n",
    "    # This is the default and can be omitted\n",
    "    # api_key=os.environ.get(\"ANTHROPIC_API_KEY\"),\n",
    ")\n",
    "\n",
    "message = client.messages.create(\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question,\n",
    "        }\n",
    "    ],\n",
    "    model=model,\n",
    ")\n",
    "print(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the relevant text piece, we select the right element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI\n",
      "Automating DevOps flows\n",
      "Efficiency blooms\n"
     ]
    }
   ],
   "source": [
    "print(message.content[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01-llm-and-prompting",
   "language": "python",
   "name": "01-llm-and-prompting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
