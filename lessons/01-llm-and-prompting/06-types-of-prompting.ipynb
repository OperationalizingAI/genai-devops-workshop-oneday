{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Prompting\n",
    "## Introduction\n",
    "To get better results from the llm, there are different prompt techniques.\n",
    "\n",
    "We've already seen the system promp, let's explore a few more techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-openai langchain-anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero shot Prompting\n",
    "\n",
    "Zero-shot prompting is a type of prompting where we don't give any examples.\n",
    "\n",
    "In this example we ask it for the sentiment and the LLM answers as it already knows what sentiment is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "prompt = \"\"\"Classify the text into neutral, negative or positive. \n",
    "Text: I think the vacation is okay.\n",
    "Sentiment:\"\"\"\n",
    "result = chat.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi shot prompting\n",
    "\n",
    "In the following code the prompt contains several examples on then expect the llm to complete them similary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"This is awesome! // Negative\n",
    "This is bad! // Positive\n",
    "Wow that movie was rad! // Positive\n",
    "What a horrible show! //\"\"\"\n",
    "result = chat.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain of Thought\n",
    "Now let's give the LLM a puzzle to solve. It answers, but the answer is not exactly right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Farmer John now has 146 chickens.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Q: Joe has 20 eggs. He buys 2 more cartons of eggs. Each carton contains 12 eggs. How many eggs does Joe have now?\n",
    "A: The answer is 44.\n",
    "\n",
    "Q: Farmer John had 93 chickens. If he sold 20 to Farmer Bill and bought twice that number more, how many chickens does Farmer John have now?\"\"\"\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "result = chat.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use a technique called \"Chain of Thought\". We do this by adding \"Let's think step by step\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Farmer John started with 93 chickens. He sold 20 to Farmer Bill, so he now has 93 - 20 = 73 chickens. He then bought twice that number more, which is 2 * 20 = 40 chickens. Therefore, Farmer John now has 73 + 40 = 113 chickens. So, Farmer John now has 113 chickens.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Q: Joe has 20 eggs. He buys 2 more cartons of eggs. Each carton contains 12 eggs. How many eggs does Joe have now? Let’s think step by step.\n",
    "A: Joe started with 20 eggs. 2 cartons of 12 eggs is 24 eggs. 20 + 24 = 44. Therefore, Joe has 44 eggs, and the answer is 44.\n",
    "\n",
    "Q: Farmer John had 93 chickens. If he sold 20 to Farmer Bill and bought twice that number more, how many chickens does Farmer John have now? Let’s think step by step.\"\"\"\n",
    "hat = ChatOpenAI(temperature=0)\n",
    "result = chat.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the default model of *ChatOpenAI* is gpt-3. If we switch the model to *gpt-4* it automatically gives the right results. As you can see it automatically applies some of the reasoning without us asking for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Farmer John initially had 93 chickens. He sold 20 chickens to Farmer Bill, so he has:\n",
      "\n",
      "93 - 20 = 73 chickens left.\n",
      "\n",
      "Then, he bought twice the number of chickens he sold, which is:\n",
      "\n",
      "2 * 20 = 40 chickens.\n",
      "\n",
      "Now, adding the chickens he bought to the remaining chickens:\n",
      "\n",
      "73 + 40 = 113 chickens.\n",
      "\n",
      "So, Farmer John now has 113 chickens.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Q: Joe has 20 eggs. He buys 2 more cartons of eggs. Each carton contains 12 eggs. How many eggs does Joe have now?\n",
    "A: The answer is 44.\n",
    "\n",
    "Q: Farmer John had 93 chickens. If he sold 20 to Farmer Bill and bought twice that number more, how many chickens does Farmer John have now?\"\"\"\n",
    "chat = ChatOpenAI(model=\"gpt-4o-mini\",temperature=0)\n",
    "result = chat.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- More prompt types described here <https://www.promptingguide.ai/techniques>\n",
    "- Chain of Thought example was inspired by <https://machinelearningmastery.com/prompt-engineering-for-effective-interaction-with-chatgpt/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01-llm-and-prompting",
   "language": "python",
   "name": "01-llm-and-prompting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
